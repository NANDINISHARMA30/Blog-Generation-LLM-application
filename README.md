# ğŸ§  Blog Generation using LLaMA 2 â€“ End-to-End LLM Project

This is an interactive LLM-based blog generation application built with **Metaâ€™s LLaMA 2**, **LangChain**, and **Streamlit**. The app allows users to input a topic, choose the desired writing style, and receive a high-quality blog article generated using LLaMA 2.

---

## ğŸ” Project Overview

With the rise of LLMs in content generation, this project focuses on:

- âœ… Structuring a local LLM pipeline using LLaMA 2  
- âœ… Leveraging LangChain for prompt templates  
- âœ… Providing an interactive UI with Streamlit  
- âœ… Creating personalized blog content with minimal input  

I built this tool to be **modular**, **lightweight**, and easy to extend â€” whether for content marketing, education, or research.

---

## âš™ï¸ Key Features

- ğŸ”— **LLaMA 2 integration** via `CTransformers` (runs locally)  
- ğŸ§  **Prompt engineering** using LangChain templates  
- ğŸ–±ï¸ **Interactive UI** built with Streamlit  
- âœï¸ **Dynamic blog content generation** based on topic, tone, and word count  
- ğŸ› ï¸ **Minimal resource requirement** (runs without GPU/cloud)  
- ğŸ’¡ Future-ready for **vector-based retrieval integration**

---

## ğŸ§± Tech Stack

- Python 3.10+
- [Meta's LLaMA 2 (GGML Quantized)]
- [LangChain]
- [CTransformers]
- [Streamlit]
- [Uvicorn] *(for API)*
- Python Box *(for cleaner configuration handling)*

---


## ğŸªª License
This project is for educational and experimental use.
Ensure compliance with Meta's LLaMA 2 license when using the model.


